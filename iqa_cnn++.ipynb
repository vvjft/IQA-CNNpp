{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOnw7qDEecAvVScRwWZR2MS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vvjft/IQA-CNNpp/blob/main/iqa_cnn%2B%2B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-A0BbLrTPdM",
        "outputId": "c67c46d7-044d-4108-feb4-108404871a16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "unrar is already the newest version (1:6.1.5-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import subprocess\n",
        "import os\n",
        "from scipy.signal import convolve2d\n",
        "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "!apt-get install unrar\n",
        "\n",
        "class data_loader:\n",
        "    ''' Parent class for database-specific loaders '''\n",
        "    def patch_files_exist(self):\n",
        "        '''Check if patch files are present in the directory.'''\n",
        "        return (os.path.exists(os.path.join(self.dir, 'normalized_distorted_images', 'training', 'patch_training.csv')) and\n",
        "                os.path.exists(os.path.join(self.dir, 'normalized_distorted_images', 'validation', 'patch_validation.csv')) and\n",
        "                os.path.exists(os.path.join(self.dir, 'normalized_distorted_images', 'test', 'patch_test.csv')))\n",
        "\n",
        "    def split_data(self, data1):\n",
        "        train_data, test_data = train_test_split(data1, test_size=0.2, random_state=40)\n",
        "        train_data, val_data = train_test_split(train_data, test_size=0.25, random_state=40)\n",
        "        return train_data, val_data, test_data\n",
        "\n",
        "    def normalize_and_slice(self, train_data, val_data, test_data, patch_size=32, cross=False):\n",
        "        def local_normalize(patch, P=3, Q=3, C=1):\n",
        "\n",
        "            kernel = np.ones((P, Q)) / (P * Q)\n",
        "            patch_mean = convolve2d(patch, kernel, boundary='symm', mode='same')\n",
        "            patch_sm = convolve2d(np.square(patch), kernel, boundary='symm', mode='same')\n",
        "            patch_std = np.sqrt(np.maximum(patch_sm - np.square(patch_mean), 0)) + C\n",
        "            patch_ln = (patch - patch_mean) / patch_std\n",
        "            return patch_ln.astype('float32')\n",
        "        def slice_image(image, patch_size=32):\n",
        "\n",
        "            height, width = image.shape[:2]\n",
        "            num_patches_y = height // patch_size\n",
        "            num_patches_x = width // patch_size\n",
        "            patch_count = 0\n",
        "            for i in range(num_patches_y):\n",
        "                for j in range(num_patches_x):\n",
        "                    patch = image[i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size]\n",
        "                    patch_path = os.path.join(output_dir_patches, f\"{os.path.splitext(image_filename)[0]}_patch_{patch_count}.bmp\")\n",
        "                    patch_filename = f\"{os.path.splitext(image_filename)[0]}_patch_{patch_count}.bmp\"\n",
        "                    cv2.imwrite(patch_path, patch)\n",
        "                    # Add patch info to the list\n",
        "                    self.patch_info_list.append([patch_filename, mos_value, distortion])\n",
        "                    patch_count += 1\n",
        "\n",
        "        sets = [(train_data, 'training'), (val_data, 'validation'), (test_data, 'test')]\n",
        "        print('Normalizing and slicing images...')\n",
        "\n",
        "        for (data, name) in sets:\n",
        "            output_dir_full = os.path.join(self.dir, 'normalized_distorted_images', name, 'full')\n",
        "            output_dir_patches = os.path.join(self.dir, 'normalized_distorted_images', name, 'patches')\n",
        "            norm_file_info_path = os.path.join(self.dir, 'normalized_distorted_images', name, f'norm_{name}.csv')\n",
        "            patch_file_info_path = os.path.join(self.dir, 'normalized_distorted_images', name, f'patch_{name}.csv')\n",
        "            os.makedirs(output_dir_full, exist_ok=True)\n",
        "            os.makedirs(output_dir_patches, exist_ok=True)\n",
        "            self.norm_info_list = []\n",
        "            self.patch_info_list = []\n",
        "            for row in data.itertuples(index=False):\n",
        "                image_filename = row[0]\n",
        "                mos_value = row[1]\n",
        "                distortion = row[2]\n",
        "                image_path = f'{self.dir}/distorted_images/{image_filename}'\n",
        "                image = cv2.imread(image_path)\n",
        "                if image is None:\n",
        "                    print(f\"Failed to load image: {image_filename}\")\n",
        "                    continue\n",
        "                # Normalize the image\n",
        "                image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "                image_normalized = local_normalize(image_gray)\n",
        "                # Save\n",
        "                image_filename = f'NORM_{image_filename.lower()}'\n",
        "                self.norm_info_list.append([image_filename, mos_value, distortion])\n",
        "                cv2.imwrite(os.path.join(output_dir_full, image_filename), image_normalized)\n",
        "                # Slice to patches\n",
        "                slice_image(image_normalized, patch_size)\n",
        "\n",
        "            norm_info_df = pd.DataFrame(self.norm_info_list, columns=['image', 'MOS', 'distortion'])\n",
        "            norm_info_df.to_csv(norm_file_info_path, index=False)\n",
        "            print(f\"[{name}]: Full image info listed in: {norm_file_info_path}.\")\n",
        "            patch_info_df = pd.DataFrame(self.patch_info_list, columns=['image', 'MOS', 'distortion'])\n",
        "            patch_info_df.to_csv(patch_file_info_path, index=False)\n",
        "            print(f\"[{name}]: Patch info listed in: {patch_file_info_path}.\")\n",
        "\n",
        "    def encode(self, dataframes):\n",
        "        '''Encodes distortion labels into one-hot vectors.'''\n",
        "        for i in range(len(dataframes)):\n",
        "            dists = dataframes[i]['distortion']\n",
        "            le = LabelEncoder()\n",
        "            y_class_encoded = le.fit_transform(dists)\n",
        "            dists_one_hot = to_categorical(y_class_encoded, num_classes=13).astype(int)\n",
        "            dataframes[i]['distortion_encoded'] = [np.array(one_hot) for one_hot in dists_one_hot]\n",
        "            dataframes[i] = dataframes[i].drop(['distortion'], axis=1)\n",
        "        return dataframes\n",
        "\n",
        "    def map2tf(self, dir, set_type, data_df):\n",
        "        '''Maps data into format excected by TensorFlow: adds chanel dimension and stores data in arrays.'''\n",
        "        images_dir = os.path.join(dir, 'normalized_distorted_images', set_type, 'patches')\n",
        "        X = []\n",
        "        y = []\n",
        "        for row in data_df.itertuples(index=False):\n",
        "            filename = row[0]\n",
        "            score = row[1]\n",
        "            file_path = os.path.join(images_dir, filename)\n",
        "            if filename.endswith('.bmp') and os.path.exists(file_path):\n",
        "                img = cv2.imread(file_path, cv2.IMREAD_UNCHANGED)\n",
        "                X.append(img)\n",
        "                y.append(score)\n",
        "            else:\n",
        "                print(f\"File not found: {file_path}\")\n",
        "        X = np.array(X)\n",
        "        y = np.array(y)\n",
        "        X = X[..., np.newaxis]\n",
        "        return X, y\n",
        "\n",
        "class tid2013_loader(data_loader):\n",
        "    def __init__(self, download=True, path='/content/databases'):\n",
        "        self.url = 'https://www.ponomarenko.info/tid2013/tid2013.rar'\n",
        "        self.dir = os.path.join(path, 'tid2013')\n",
        "        self.file_path = os.path.join(self.dir, 'tid2013.rar')\n",
        "        self.distortion_mapping = {1: 'wn', 2:'wnc', 3:'scn', 4:'mn', 5:'hfn', 6:'in', 7:'qn', 8: 'gblur', 9:'idn', 10: 'jpeg', 11: 'jp2k', 12:'jpegte', 13:'jp2kte'} # According to TID2013 documentation\n",
        "\n",
        "        os.makedirs(self.dir, exist_ok=True)\n",
        "        if download:\n",
        "            self.download()\n",
        "        if self.patch_files_exist():\n",
        "            print(\"Patch files found. Loading patched data...\")\n",
        "            data = self.__load_patched_data()\n",
        "        else:\n",
        "            data = self.prepare_data()\n",
        "        #self.train, self.val, self.test = self.encode(data)\n",
        "        print('Mapping data to TensorFlow format...')\n",
        "        self.train = self.map2tf(self.dir, 'training', data[0])\n",
        "        self.val = self.map2tf(self.dir, 'validation', data[1])\n",
        "        self.test = self.map2tf(self.dir, 'test', data[2])\n",
        "\n",
        "    def __load_patched_data(self):\n",
        "        # Load the existing patched data\n",
        "        columns=['image', 'MOS', 'distortion']\n",
        "        train_data = pd.read_csv(os.path.join(self.dir, 'normalized_distorted_images', 'training', 'patch_training.csv'))\n",
        "        val_data = pd.read_csv(os.path.join(self.dir, 'normalized_distorted_images', 'validation', 'patch_validation.csv'))\n",
        "        test_data = pd.read_csv(os.path.join(self.dir, 'normalized_distorted_images', 'test', 'patch_test.csv'))\n",
        "        return [train_data, val_data, test_data]\n",
        "        print(\"Data loaded successfully.\")\n",
        "\n",
        "    def download(self):\n",
        "        try:\n",
        "            print(f\"Downloading dataset from {self.url}...\")\n",
        "            !wget {self.url} -P {self.dir}\n",
        "            !unrar x -inul {os.path.join(self.dir, 'tid2013.rar')} {self.dir}\n",
        "            print(f\"Dataset downloaded and extracted in '{self.dir}'\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to download dataset: {e}.\")\n",
        "            return False\n",
        "\n",
        "    def prepare_data(self, filter=True):\n",
        "        '''Processes data.'''\n",
        "        data_path = os.path.join(self.dir, 'mos_with_names.txt')\n",
        "        data = pd.read_csv(data_path, header=None, delimiter=' ')\n",
        "        data = data.iloc[:, [1, 0]]  # swap column order\n",
        "        data.columns = ['image', 'MOS']\n",
        "        data['distortion'] = data['image'].apply(lambda x: self.distortion_mapping.get(int(x.split('_')[1]), 'other'))\n",
        "        if filter:\n",
        "            data = data[data['distortion'].isin(self.distortion_mapping.values())]\n",
        "        data.to_csv('databases/tid2013/mos_with_names.csv', index=False)\n",
        "\n",
        "        train_data, val_data, test_data = self.split_data(data)\n",
        "        self.normalize_and_slice(train_data, val_data, test_data)\n",
        "\n",
        "        train_data = pd.read_csv(f'{self.dir}/normalized_distorted_images/training/patch_training.csv')\n",
        "        val_data = pd.read_csv(f'{self.dir}/normalized_distorted_images/validation/patch_validation.csv')\n",
        "        test_data = pd.read_csv(f'{self.dir}/normalized_distorted_images/test/patch_test.csv')\n",
        "        return [train_data, val_data, test_data]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the download is slow, stop it, delete databases directory (!rm)\n",
        " and run it again."
      ],
      "metadata": {
        "id": "k1nG-AgVZX5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r 'databases/'\n",
        "tid2013_loader = tid2013_loader(download=True)\n",
        "\n",
        "X_train, y_train = tid2013_loader.train\n",
        "X_val, y_val = tid2013_loader.val\n",
        "X_test, y_test = tid2013_loader.test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GLRKt2kneZP",
        "outputId": "15032749-3e62-41fa-9b4d-b91700f3de11"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset from https://www.ponomarenko.info/tid2013/tid2013.rar...\n",
            "--2024-08-07 22:12:14--  https://www.ponomarenko.info/tid2013/tid2013.rar\n",
            "Resolving www.ponomarenko.info (www.ponomarenko.info)... 154.41.250.81, 2a02:4780:1d:d798:ce36:b6bb:c241:542e\n",
            "Connecting to www.ponomarenko.info (www.ponomarenko.info)|154.41.250.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 957680241 (913M) [application/x-rar-compressed]\n",
            "Saving to: ‘/content/databases/tid2013/tid2013.rar’\n",
            "\n",
            "tid2013.rar         100%[===================>] 913.31M  40.7MB/s    in 1m 50s  \n",
            "\n",
            "2024-08-07 22:14:05 (8.28 MB/s) - ‘/content/databases/tid2013/tid2013.rar’ saved [957680241/957680241]\n",
            "\n",
            "Dataset downloaded and extracted in '/content/databases/tid2013'\n",
            "Normalizing and slicing images...\n",
            "[training]: Full image info listed in: /content/databases/tid2013/normalized_distorted_images/training/norm_training.csv.\n",
            "[training]: Patch info listed in: /content/databases/tid2013/normalized_distorted_images/training/patch_training.csv.\n",
            "[validation]: Full image info listed in: /content/databases/tid2013/normalized_distorted_images/validation/norm_validation.csv.\n",
            "[validation]: Patch info listed in: /content/databases/tid2013/normalized_distorted_images/validation/patch_validation.csv.\n",
            "[test]: Full image info listed in: /content/databases/tid2013/normalized_distorted_images/test/norm_test.csv.\n",
            "[test]: Patch info listed in: /content/databases/tid2013/normalized_distorted_images/test/patch_test.csv.\n",
            "Mapping data to TensorFlow format...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(32, 32, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZgZvm-Oaw5x",
        "outputId": "276f8ffa-2cc6-4160-a4c3-c628020268d7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 2.3427 - mae: 1.1304 - val_loss: 1.2067 - val_mae: 0.8818\n",
            "Epoch 2/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 1.0827 - mae: 0.8360 - val_loss: 1.1121 - val_mae: 0.8416\n",
            "Epoch 3/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 1.0211 - mae: 0.8066 - val_loss: 1.0569 - val_mae: 0.8179\n",
            "Epoch 4/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 0.9796 - mae: 0.7870 - val_loss: 1.0329 - val_mae: 0.8122\n",
            "Epoch 5/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.9484 - mae: 0.7718 - val_loss: 1.0472 - val_mae: 0.8091\n",
            "Epoch 6/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 0.9252 - mae: 0.7603 - val_loss: 1.0346 - val_mae: 0.8074\n",
            "Epoch 7/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.9049 - mae: 0.7501 - val_loss: 1.0216 - val_mae: 0.8090\n",
            "Epoch 8/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.8786 - mae: 0.7395 - val_loss: 1.1015 - val_mae: 0.8286\n",
            "Epoch 9/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.8740 - mae: 0.7377 - val_loss: 1.0154 - val_mae: 0.7884\n",
            "Epoch 10/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.8516 - mae: 0.7258 - val_loss: 1.1005 - val_mae: 0.8146\n",
            "Epoch 11/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.8374 - mae: 0.7181 - val_loss: 1.0413 - val_mae: 0.7981\n",
            "Epoch 12/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.8278 - mae: 0.7133 - val_loss: 0.9972 - val_mae: 0.7952\n",
            "Epoch 13/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.8130 - mae: 0.7075 - val_loss: 1.0147 - val_mae: 0.8051\n",
            "Epoch 14/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.7979 - mae: 0.6993 - val_loss: 1.0095 - val_mae: 0.7915\n",
            "Epoch 15/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 0.7929 - mae: 0.6975 - val_loss: 1.0083 - val_mae: 0.7852\n",
            "Epoch 16/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.7810 - mae: 0.6921 - val_loss: 1.0058 - val_mae: 0.7858\n",
            "Epoch 17/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.7718 - mae: 0.6875 - val_loss: 1.0365 - val_mae: 0.7951\n",
            "Epoch 18/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.7599 - mae: 0.6818 - val_loss: 1.0420 - val_mae: 0.7918\n",
            "Epoch 19/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.7499 - mae: 0.6756 - val_loss: 1.0447 - val_mae: 0.7986\n",
            "Epoch 20/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.7395 - mae: 0.6728 - val_loss: 1.0449 - val_mae: 0.7910\n",
            "Epoch 21/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.7338 - mae: 0.6685 - val_loss: 1.0193 - val_mae: 0.7887\n",
            "Epoch 22/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - loss: 0.7272 - mae: 0.6647 - val_loss: 1.0471 - val_mae: 0.7973\n",
            "Epoch 23/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.7175 - mae: 0.6603 - val_loss: 1.0384 - val_mae: 0.7970\n",
            "Epoch 24/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.7097 - mae: 0.6561 - val_loss: 1.0669 - val_mae: 0.8049\n",
            "Epoch 25/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.7074 - mae: 0.6546 - val_loss: 1.0993 - val_mae: 0.8012\n",
            "Epoch 26/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.7032 - mae: 0.6518 - val_loss: 1.0621 - val_mae: 0.7942\n",
            "Epoch 27/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.6928 - mae: 0.6468 - val_loss: 1.0395 - val_mae: 0.8024\n",
            "Epoch 28/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.6881 - mae: 0.6452 - val_loss: 1.1073 - val_mae: 0.8089\n",
            "Epoch 29/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.6771 - mae: 0.6389 - val_loss: 1.0735 - val_mae: 0.8038\n",
            "Epoch 30/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.6668 - mae: 0.6337 - val_loss: 1.0855 - val_mae: 0.8079\n",
            "Epoch 31/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.6672 - mae: 0.6338 - val_loss: 1.1121 - val_mae: 0.8052\n",
            "Epoch 32/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.6649 - mae: 0.6327 - val_loss: 1.0971 - val_mae: 0.8105\n",
            "Epoch 33/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.6544 - mae: 0.6273 - val_loss: 1.1232 - val_mae: 0.8118\n",
            "Epoch 34/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 0.6515 - mae: 0.6266 - val_loss: 1.0954 - val_mae: 0.8027\n",
            "Epoch 35/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.6439 - mae: 0.6214 - val_loss: 1.0960 - val_mae: 0.8126\n",
            "Epoch 36/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - loss: 0.6461 - mae: 0.6229 - val_loss: 1.0891 - val_mae: 0.8045\n",
            "Epoch 37/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.6350 - mae: 0.6174 - val_loss: 1.0827 - val_mae: 0.8004\n",
            "Epoch 38/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.6351 - mae: 0.6149 - val_loss: 1.1025 - val_mae: 0.8112\n",
            "Epoch 39/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.6300 - mae: 0.6128 - val_loss: 1.0890 - val_mae: 0.8123\n",
            "Epoch 40/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.6214 - mae: 0.6088 - val_loss: 1.0947 - val_mae: 0.8073\n",
            "Epoch 41/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.6183 - mae: 0.6078 - val_loss: 1.1204 - val_mae: 0.8122\n",
            "Epoch 42/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.6203 - mae: 0.6076 - val_loss: 1.0911 - val_mae: 0.8087\n",
            "Epoch 43/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.6115 - mae: 0.6041 - val_loss: 1.1114 - val_mae: 0.8073\n",
            "Epoch 44/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.6089 - mae: 0.6020 - val_loss: 1.1200 - val_mae: 0.8113\n",
            "Epoch 45/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.6063 - mae: 0.5999 - val_loss: 1.1420 - val_mae: 0.8172\n",
            "Epoch 46/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.5972 - mae: 0.5957 - val_loss: 1.1072 - val_mae: 0.8106\n",
            "Epoch 47/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.5930 - mae: 0.5932 - val_loss: 1.0980 - val_mae: 0.8076\n",
            "Epoch 48/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.5868 - mae: 0.5898 - val_loss: 1.1065 - val_mae: 0.8122\n",
            "Epoch 49/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.5858 - mae: 0.5895 - val_loss: 1.2213 - val_mae: 0.8352\n",
            "Epoch 50/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.5806 - mae: 0.5857 - val_loss: 1.1416 - val_mae: 0.8153\n",
            "Epoch 51/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.5785 - mae: 0.5850 - val_loss: 1.1568 - val_mae: 0.8202\n",
            "Epoch 52/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 0.5747 - mae: 0.5837 - val_loss: 1.1415 - val_mae: 0.8179\n",
            "Epoch 53/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.5753 - mae: 0.5828 - val_loss: 1.1377 - val_mae: 0.8163\n",
            "Epoch 54/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.5718 - mae: 0.5808 - val_loss: 1.1306 - val_mae: 0.8138\n",
            "Epoch 55/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.5727 - mae: 0.5815 - val_loss: 1.1580 - val_mae: 0.8243\n",
            "Epoch 56/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.5640 - mae: 0.5764 - val_loss: 1.1304 - val_mae: 0.8139\n",
            "Epoch 57/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.5599 - mae: 0.5738 - val_loss: 1.1453 - val_mae: 0.8200\n",
            "Epoch 58/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.5573 - mae: 0.5721 - val_loss: 1.1391 - val_mae: 0.8171\n",
            "Epoch 59/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.5541 - mae: 0.5713 - val_loss: 1.1432 - val_mae: 0.8259\n",
            "Epoch 60/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.5693 - mae: 0.5769 - val_loss: 1.1534 - val_mae: 0.8224\n",
            "Epoch 61/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.5502 - mae: 0.5683 - val_loss: 1.1619 - val_mae: 0.8247\n",
            "Epoch 62/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 0.5485 - mae: 0.5679 - val_loss: 1.1741 - val_mae: 0.8256\n",
            "Epoch 63/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.5441 - mae: 0.5646 - val_loss: 1.2212 - val_mae: 0.8382\n",
            "Epoch 64/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.5411 - mae: 0.5631 - val_loss: 1.1806 - val_mae: 0.8277\n",
            "Epoch 65/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.5401 - mae: 0.5627 - val_loss: 1.1819 - val_mae: 0.8280\n",
            "Epoch 66/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 0.5381 - mae: 0.5619 - val_loss: 1.1679 - val_mae: 0.8254\n",
            "Epoch 67/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 0.5402 - mae: 0.5622 - val_loss: 1.1929 - val_mae: 0.8316\n",
            "Epoch 68/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.5320 - mae: 0.5579 - val_loss: 1.1626 - val_mae: 0.8219\n",
            "Epoch 69/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.5256 - mae: 0.5543 - val_loss: 1.1534 - val_mae: 0.8217\n",
            "Epoch 70/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: 0.5285 - mae: 0.5568 - val_loss: 1.1831 - val_mae: 0.8274\n",
            "Epoch 71/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - loss: 0.5238 - mae: 0.5524 - val_loss: 1.1685 - val_mae: 0.8296\n",
            "Epoch 72/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.5235 - mae: 0.5535 - val_loss: 1.2037 - val_mae: 0.8318\n",
            "Epoch 73/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.5210 - mae: 0.5512 - val_loss: 1.1857 - val_mae: 0.8358\n",
            "Epoch 74/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.5210 - mae: 0.5507 - val_loss: 1.1827 - val_mae: 0.8272\n",
            "Epoch 75/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.5163 - mae: 0.5497 - val_loss: 1.1600 - val_mae: 0.8265\n",
            "Epoch 76/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.5127 - mae: 0.5467 - val_loss: 1.1773 - val_mae: 0.8281\n",
            "Epoch 77/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 0.5176 - mae: 0.5487 - val_loss: 1.2023 - val_mae: 0.8306\n",
            "Epoch 78/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.5162 - mae: 0.5470 - val_loss: 1.1931 - val_mae: 0.8293\n",
            "Epoch 79/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.5110 - mae: 0.5461 - val_loss: 1.2034 - val_mae: 0.8337\n",
            "Epoch 80/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.5121 - mae: 0.5458 - val_loss: 1.1944 - val_mae: 0.8327\n",
            "Epoch 81/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.5167 - mae: 0.5483 - val_loss: 1.2039 - val_mae: 0.8367\n",
            "Epoch 82/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.4996 - mae: 0.5385 - val_loss: 1.1765 - val_mae: 0.8347\n",
            "Epoch 83/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.5062 - mae: 0.5418 - val_loss: 1.2250 - val_mae: 0.8431\n",
            "Epoch 84/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.5022 - mae: 0.5404 - val_loss: 1.1830 - val_mae: 0.8340\n",
            "Epoch 85/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 0.4979 - mae: 0.5381 - val_loss: 1.2628 - val_mae: 0.8475\n",
            "Epoch 86/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.4988 - mae: 0.5381 - val_loss: 1.1973 - val_mae: 0.8418\n",
            "Epoch 87/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.4969 - mae: 0.5360 - val_loss: 1.2387 - val_mae: 0.8441\n",
            "Epoch 88/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.4923 - mae: 0.5341 - val_loss: 1.2211 - val_mae: 0.8435\n",
            "Epoch 89/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.4939 - mae: 0.5356 - val_loss: 1.2229 - val_mae: 0.8419\n",
            "Epoch 90/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 0.4941 - mae: 0.5348 - val_loss: 1.2691 - val_mae: 0.8517\n",
            "Epoch 91/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.4907 - mae: 0.5331 - val_loss: 1.2489 - val_mae: 0.8500\n",
            "Epoch 92/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.4868 - mae: 0.5311 - val_loss: 1.2457 - val_mae: 0.8430\n",
            "Epoch 93/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.4845 - mae: 0.5303 - val_loss: 1.2282 - val_mae: 0.8473\n",
            "Epoch 94/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.4832 - mae: 0.5280 - val_loss: 1.1934 - val_mae: 0.8398\n",
            "Epoch 95/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.4821 - mae: 0.5277 - val_loss: 1.2222 - val_mae: 0.8428\n",
            "Epoch 96/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.4805 - mae: 0.5269 - val_loss: 1.2476 - val_mae: 0.8481\n",
            "Epoch 97/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.4860 - mae: 0.5291 - val_loss: 1.3006 - val_mae: 0.8593\n",
            "Epoch 98/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 0.4762 - mae: 0.5240 - val_loss: 1.2068 - val_mae: 0.8362\n",
            "Epoch 99/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: 0.4753 - mae: 0.5229 - val_loss: 1.2053 - val_mae: 0.8372\n",
            "Epoch 100/100\n",
            "\u001b[1m5850/5850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.4770 - mae: 0.5244 - val_loss: 1.2395 - val_mae: 0.8458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', loss)\n",
        "print('Test MAE:', mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1YpQZcgZAgF",
        "outputId": "72d420c3-9d90-49f2-a9b8-e7d11a364de2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 1.3141990900039673\n",
            "Test MAE: 0.8770523071289062\n"
          ]
        }
      ]
    }
  ]
}